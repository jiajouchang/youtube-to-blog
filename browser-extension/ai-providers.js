/**
 * AI Providers Module for Browser Extension
 * 
 * ÊîØÊè¥Â§öÂÄã AI ‰æõÊáâÂïÜÁöÑÁµ±‰∏ÄÊé•Âè£
 * ‰ΩøÁî®ÂéüÁîü fetch API Áõ¥Êé•ÂëºÂè´ÂêÑ‰æõÊáâÂïÜÁöÑ REST API
 */

import { getMessage } from './i18n.js';

// ============================================================================
// Provider Configurations
// ============================================================================

const AI_PROVIDERS = {
    gemini: {
        id: 'gemini',
        name: 'Google Gemini',
        free: true,
        apiUrl: 'https://aistudio.google.com/app/apikey',
        models: [
            { id: 'gemini-2.5-flash', name: 'Gemini 2.5 Flash', badge: '‚ö° Êé®Ëñ¶' },
            { id: 'gemini-2.5-pro', name: 'Gemini 2.5 Pro', badge: 'üß† Ê∑±Â∫¶ÊÄùËÄÉ' },
            { id: 'gemini-2.0-flash', name: 'Gemini 2.0 Flash', badge: '' },
            { id: 'gemini-1.5-flash', name: 'Gemini 1.5 Flash', badge: '' },
            { id: 'gemini-1.5-pro', name: 'Gemini 1.5 Pro', badge: '' },
        ],
        features: ['ÂÖçË≤ª‰ΩøÁî®', 'Â§öÊ®°ÊÖã', 'Èï∑ÊñáÊú¨']
    },
    groq: {
        id: 'groq',
        name: 'Groq',
        free: true,
        apiUrl: 'https://console.groq.com/keys',
        models: [
            { id: 'llama-3.3-70b-versatile', name: 'Llama 3.3 70B', badge: 'üöÄ Êé®Ëñ¶' },
            { id: 'llama-3.1-70b-versatile', name: 'Llama 3.1 70B', badge: '‚≠ê È´òÂìÅË≥™' },
            { id: 'llama-3.1-8b-instant', name: 'Llama 3.1 8B', badge: '‚ö° Ê•µÈÄü' },
            { id: 'mixtral-8x7b-32768', name: 'Mixtral 8x7B', badge: 'üîÄ MoE' },
            { id: 'gemma2-9b-it', name: 'Gemma 2 9B', badge: 'üî∑ Google' },
        ],
        features: ['ÂÖçË≤ª‰ΩøÁî®', 'Ë∂ÖÂø´ÈÄüÂ∫¶', 'ÈñãÊ∫êÊ®°Âûã']
    },
    openai: {
        id: 'openai',
        name: 'OpenAI',
        free: false,
        apiUrl: 'https://platform.openai.com/api-keys',
        models: [
            { id: 'gpt-4o', name: 'GPT-4o', badge: 'üèÜ Êé®Ëñ¶' },
            { id: 'gpt-4o-mini', name: 'GPT-4o Mini', badge: 'üí∞ Á∂ìÊøü' },
            { id: 'gpt-4-turbo', name: 'GPT-4 Turbo', badge: '' },
            { id: 'o1-mini', name: 'O1 Mini', badge: 'üß† Êé®ÁêÜ' },
        ],
        features: ['È´òÂìÅË≥™', 'Â§öË™ûË®Ä', 'ÂáΩÊï∏Ë™øÁî®']
    },
    anthropic: {
        id: 'anthropic',
        name: 'Anthropic Claude',
        free: false,
        apiUrl: 'https://console.anthropic.com',
        models: [
            { id: 'claude-sonnet-4-20250514', name: 'Claude Sonnet 4', badge: '‚ö° Êé®Ëñ¶' },
            { id: 'claude-3-5-sonnet-20241022', name: 'Claude 3.5 Sonnet', badge: 'üéØ Á©©ÂÆö' },
            { id: 'claude-3-5-haiku-20241022', name: 'Claude 3.5 Haiku', badge: 'üí® Âø´ÈÄü' },
            { id: 'claude-3-opus-20240229', name: 'Claude 3 Opus', badge: 'üß† ÊúÄÂº∑' },
        ],
        features: ['Èï∑ÊñáÊú¨', 'Á≤æÁ¢∫ÁêÜËß£', 'Á®ãÂºèÁ¢º']
    },
    deepseek: {
        id: 'deepseek',
        name: 'DeepSeek',
        free: false,
        apiUrl: 'https://platform.deepseek.com',
        models: [
            { id: 'deepseek-chat', name: 'DeepSeek Chat', badge: 'üí∞ Ë∂Ö‰ΩéÂÉπ' },
            { id: 'deepseek-coder', name: 'DeepSeek Coder', badge: 'üíª Á®ãÂºèÁ¢º' },
        ],
        features: ['Ê•µËá¥ÊÄßÂÉπÊØî', 'GPT-4Á¥öÂà•', '‰∏≠Ëã±ÊñáÂÑ™ÁßÄ']
    }
};

// ============================================================================
// API Call Functions
// ============================================================================

/**
 * Âª∫Á´ãÊ®ôÊ∫ñÂåñÁöÑ prompt
 */
const PROMPT_TEMPLATES = {
    'zh_TW': {
        professional: 'Â∞àÊ•≠‰∏îÊ≠£Âºè',
        template: (transcript, language, styleDesc) => `‰Ω†ÊòØ‰∏Ä‰ΩçÂ∞àÊ•≠ÁöÑÈÉ®ËêΩÊ†º‰ΩúÂÆ∂Âíå SEO Â∞àÂÆ∂„ÄÇË´ãÂ∞á‰ª•‰∏ã YouTube Ë¶ñÈ†ªÊñáÂ≠óÁ®øËΩâÊèõÁÇ∫‰∏ÄÁØáÊ†ºÂºèÂÆåÁæé„ÄÅSEO ÂÑ™ÂåñÁöÑÈÉ®ËêΩÊ†ºÊñáÁ´†„ÄÇ

ÊñáÁ´†È¢®Ê†ºÔºö${styleDesc}
Ëº∏Âá∫Ë™ûË®ÄÔºö${language}

Ë¶ÅÊ±ÇÔºö
1. ÂâµÂª∫‰∏ÄÂÄãÂê∏Âºï‰∫∫ÁöÑÊ®ôÈ°åÔºà‰ΩøÁî® # Ê®ôÈ°åÊ†ºÂºèÔºâ
2. Êí∞ÂØ´Âºï‰∫∫ÂÖ•ÂãùÁöÑÈñãÈ†≠ÊÆµËêΩ
3. Â∞áÂÖßÂÆπÁµÑÁπîÊàêÊ∏ÖÊô∞ÁöÑÁ´†ÁØÄÔºà‰ΩøÁî® ## Âíå ### Ê®ôÈ°åÔºâ
4. ‰ΩøÁî®È†ÖÁõÆÁ¨¶ËôüÂíåÁ∑®ËôüÂàóË°®‰æÜÊèêÈ´òÂèØËÆÄÊÄß
5. Âú®ÈÅ©Áï∂ÁöÑÂú∞ÊñπÊ∑ªÂä†ÈáçÈªûÂº∑Ë™øÔºà‰ΩøÁî® **Á≤óÈ´î**Ôºâ
6. Êí∞ÂØ´‰∏ÄÂÄãÁ∏ΩÁµêÊÆµËêΩ
7. Á¢∫‰øùË™ûË®ÄÊµÅÊö¢„ÄÅÂ∞àÊ•≠‰∏îÊòìÊñºÁêÜËß£
8. ÂÑ™Âåñ SEO ÈóúÈçµÂ≠óÁöÑ‰ΩøÁî®

ÂéüÂßãÊñáÂ≠óÁ®øÔºö
${transcript}

Ë´ãÁîüÊàêÂÆåÊï¥ÁöÑ Markdown Ê†ºÂºèÈÉ®ËêΩÊ†ºÊñáÁ´†Ôºö`
    },
    'en': {
        professional: 'Professional and Formal',
        template: (transcript, language, styleDesc) => `You are a professional blog writer and SEO expert. Please convert the following YouTube video transcript into a perfectly formatted, SEO-optimized blog article.

Article Style: ${styleDesc} (Professional)
Output Language: ${language}

Requirements:
1. Create a catchy Title (use # Title format)
2. Write an engaging Introduction
3. Organize content into clear Sections (use ## and ### headings)
4. Use Bullet Points and Numbered Lists for readability
5. Use Bold text for emphasis where appropriate
6. Write a Summary/Conclusion
7. Ensure the tone is professional, fluent, and easy to understand
8. Optimize for SEO keywords

Original Transcript:
${transcript}

Please generate the complete blog article in Markdown format:`
    }
};

/**
 * Âª∫Á´ãÊ®ôÊ∫ñÂåñÁöÑ prompt
 */
function buildPrompt(transcript, language = 'English', style = 'professional') {
    // Determine locale template to use based on output language
    // If output is Chinese, use Chinese template (instructions in Chinese)
    // If output is English, use English template (instructions in English)
    let locale = 'en';
    if (language === 'Traditional Chinese' || language === 'ÁπÅÈ´î‰∏≠Êñá' || language === 'zh-TW') {
        locale = 'zh_TW';
    }

    const templateConfig = PROMPT_TEMPLATES[locale];
    const styleDesc = templateConfig[style] || templateConfig.professional;

    return templateConfig.template(transcript, language, styleDesc);
}

/**
 * Gemini API Ë™øÁî®
 */
async function callGeminiAPI(apiKey, model, prompt) {
    const { GoogleGenerativeAI } = await import('./google-generative-ai.js');

    const genAI = new GoogleGenerativeAI(apiKey);
    const geminiModel = genAI.getGenerativeModel({ model });

    const result = await geminiModel.generateContent(prompt);
    const response = await result.response;
    return response.text();
}

/**
 * Groq API Ë™øÁî® (OpenAI Áõ∏ÂÆπÊ†ºÂºè)
 */
async function callGroqAPI(apiKey, model, prompt) {
    const response = await fetch('https://api.groq.com/openai/v1/chat/completions', {
        method: 'POST',
        headers: {
            'Content-Type': 'application/json',
            'Authorization': `Bearer ${apiKey}`,
        },
        body: JSON.stringify({
            model: model,
            messages: [{ role: 'user', content: prompt }],
            temperature: 0.7,
            max_tokens: 4096,
        }),
    });

    if (!response.ok) {
        const error = await response.json().catch(() => ({ error: { message: response.statusText } }));
        throw new Error(error.error?.message || `Groq API ÈåØË™§: ${response.status}`);
    }

    const data = await response.json();
    return data.choices[0].message.content;
}

/**
 * OpenAI API Ë™øÁî®
 */
async function callOpenAIAPI(apiKey, model, prompt) {
    const response = await fetch('https://api.openai.com/v1/chat/completions', {
        method: 'POST',
        headers: {
            'Content-Type': 'application/json',
            'Authorization': `Bearer ${apiKey}`,
        },
        body: JSON.stringify({
            model: model,
            messages: [{ role: 'user', content: prompt }],
            temperature: 0.7,
        }),
    });

    if (!response.ok) {
        const error = await response.json().catch(() => ({ error: { message: response.statusText } }));
        throw new Error(error.error?.message || `OpenAI API ÈåØË™§: ${response.status}`);
    }

    const data = await response.json();
    return data.choices[0].message.content;
}

/**
 * Anthropic Claude API Ë™øÁî®
 */
async function callAnthropicAPI(apiKey, model, prompt) {
    const response = await fetch('https://api.anthropic.com/v1/messages', {
        method: 'POST',
        headers: {
            'Content-Type': 'application/json',
            'x-api-key': apiKey,
            'anthropic-version': '2023-06-01',
            'anthropic-dangerous-direct-browser-access': 'true',
        },
        body: JSON.stringify({
            model: model,
            max_tokens: 4096,
            messages: [{ role: 'user', content: prompt }],
        }),
    });

    if (!response.ok) {
        const error = await response.json().catch(() => ({ error: { message: response.statusText } }));
        throw new Error(error.error?.message || `Claude API ÈåØË™§: ${response.status}`);
    }

    const data = await response.json();
    return data.content[0].text;
}

/**
 * DeepSeek API Ë™øÁî® (OpenAI Áõ∏ÂÆπÊ†ºÂºè)
 */
async function callDeepSeekAPI(apiKey, model, prompt) {
    const response = await fetch('https://api.deepseek.com/v1/chat/completions', {
        method: 'POST',
        headers: {
            'Content-Type': 'application/json',
            'Authorization': `Bearer ${apiKey}`,
        },
        body: JSON.stringify({
            model: model,
            messages: [{ role: 'user', content: prompt }],
            temperature: 0.7,
        }),
    });

    if (!response.ok) {
        const error = await response.json().catch(() => ({ error: { message: response.statusText } }));
        throw new Error(error.error?.message || `DeepSeek API ÈåØË™§: ${response.status}`);
    }

    const data = await response.json();
    return data.choices[0].message.content;
}

// ============================================================================
// Main Export Functions
// ============================================================================

/**
 * ÂèñÂæóÊâÄÊúâ‰æõÊáâÂïÜÈÖçÁΩÆ
 */
function getProviders() {
    return AI_PROVIDERS;
}

/**
 * ÂèñÂæóÊåáÂÆö‰æõÊáâÂïÜÁöÑË≥áË®ä
 */
function getProviderInfo(providerId) {
    return AI_PROVIDERS[providerId] || null;
}

/**
 * Áµ±‰∏ÄÁöÑÂÖßÂÆπÁîüÊàêÂáΩÊï∏
 */
async function generateContent(providerId, apiKey, model, transcript, options = {}) {
    // Default to English if not specified
    const { language = 'English', style = 'professional' } = options;
    const prompt = buildPrompt(transcript, language, style);

    console.log(`[AI Providers] Calling ${providerId} API with model: ${model}`);

    try {
        let result;

        switch (providerId) {
            case 'gemini':
                result = await callGeminiAPI(apiKey, model, prompt);
                break;
            case 'groq':
                result = await callGroqAPI(apiKey, model, prompt);
                break;
            case 'openai':
                result = await callOpenAIAPI(apiKey, model, prompt);
                break;
            case 'anthropic':
                result = await callAnthropicAPI(apiKey, model, prompt);
                break;
            case 'deepseek':
                result = await callDeepSeekAPI(apiKey, model, prompt);
                break;
            default:
                throw new Error(`‰∏çÊîØÊè¥ÁöÑ AI ‰æõÊáâÂïÜ: ${providerId}`);
        }

        if (!result || result.trim().length === 0) {
            throw new Error(getMessage('errAiNoContent'));
        }

        console.log(`[AI Providers] Success! Generated ${result.length} characters`);
        return result;

    } catch (error) {
        console.error(`[AI Providers] Error:`, error);
        throw new Error(getFriendlyErrorMessage(error, providerId));
    }
}

/**
 * Áî¢ÁîüÂèãÂñÑÁöÑÈåØË™§Ë®äÊÅØ
 */
function getFriendlyErrorMessage(error, providerId) {
    const rawMessage = error.message || error.toString();
    const providerName = AI_PROVIDERS[providerId]?.name || providerId;
    const lowerMsg = rawMessage.toLowerCase();

    // 1. ÈÖçÈ°ç/ÈÄüÁéáÈôêÂà∂ (Quota/Rate Limit)
    if (rawMessage.includes('429') ||
        lowerMsg.includes('quota') ||
        lowerMsg.includes('rate limit') ||
        lowerMsg.includes('resource has been exhausted')) {
        return getMessage('errApiQuota', [providerName]);
    }

    // 2. Ë™çË≠âÈåØË™§ (Auth)
    if (rawMessage.includes('401') ||
        rawMessage.includes('403') ||
        (lowerMsg.includes('api key') && (lowerMsg.includes('invalid') || lowerMsg.includes('incorrect'))) ||
        lowerMsg.includes('unauthorized')) {
        return getMessage('errApiAuth');
    }

    // 3. Ê®°ÂûãÈåØË™§ (Model)
    if (lowerMsg.includes('model') && lowerMsg.includes('not found')) {
        return getMessage('errApiModel');
    }

    // 4. ÊúçÂãôÈÅéËºâ (Overloaded)
    if (lowerMsg.includes('overloaded') || rawMessage.includes('503')) {
        return getMessage('errApiOverloaded', [providerName]);
    }

    // 5. Á∂≤Ë∑Ø/ÂÆâÂÖ®ÊÄßÈåØË™§
    if (lowerMsg.includes('fetch') || lowerMsg.includes('network') || lowerMsg.includes('security')) {
        return getMessage('errApiNetwork');
    }

    // 6. ÂÖßÂÆπÈÅéÊøæ/ÂÆâÂÖ®Ë®≠ÂÆö (Safety)
    if (lowerMsg.includes('safety') || lowerMsg.includes('harmful') || lowerMsg.includes('blocked')) {
        return getMessage('errApiSafety');
    }

    // 7. ÈÅéÊøæÊéâÈÅéÈï∑ÁöÑÊäÄË°ìÊÄßÈåØË™§Ë®äÊÅØ
    if (rawMessage.length > 150 || rawMessage.trim().startsWith('{') || rawMessage.includes('Error:')) {
        return getMessage('errUnexpected') + ` (${rawMessage.substring(0, 50)}...)`;
    }

    return `‚ùå Error: ${rawMessage}`;
}

// Export for use in sidepanel.js
export { AI_PROVIDERS, getProviders, getProviderInfo, generateContent, buildPrompt };
